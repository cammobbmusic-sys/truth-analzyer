# AI Model Evaluation Framework Configuration
# Comprehensive settings for systematic model evaluation and comparison

# System Settings
system:
  name: "Multi-Agent Truth Analyzer Evaluation Framework"
  version: "1.0.0"
  description: "Rigorous evaluation system for AI model performance analysis"

# Data Collection Settings
data_collection:
  enabled: true
  auto_save: true
  save_interval: 10  # Save after every N evaluations
  max_history: 10000  # Maximum evaluations to keep in memory
  export_formats: ["json", "csv"]  # Supported export formats

# Evaluation Metrics Configuration
metrics:
  # Quantitative Metrics (numerical, objective)
  quantitative:
    response_time:
      name: "Response Time"
      description: "Time taken to generate response"
      unit: "seconds"
      higher_is_better: false
      weight: 0.2
      thresholds:
        excellent: 1.0
        good: 2.0
        poor: 5.0

    accuracy:
      name: "Accuracy"
      description: "Correctness of the response"
      unit: "score"
      higher_is_better: true
      weight: 0.4
      min_value: 0.0
      max_value: 1.0

    cost_efficiency:
      name: "Cost Efficiency"
      description: "Performance per unit cost"
      unit: "score_per_dollar"
      higher_is_better: true
      weight: 0.05

  # Qualitative Metrics (subjective, requires human judgment)
  qualitative:
    relevance:
      name: "Relevance"
      description: "How relevant the response is to the query"
      unit: "score"
      higher_is_better: true
      weight: 0.2
      min_value: 0.0
      max_value: 1.0

    creativity:
      name: "Creativity"
      description: "Originality and creativity in response"
      unit: "score"
      higher_is_better: true
      weight: 0.15
      min_value: 0.0
      max_value: 1.0

# Genre-Specific Evaluation Settings
genres:
  factual_qa:
    name: "Factual Question Answering"
    description: "Questions requiring factual knowledge and accuracy"
    primary_metrics: ["accuracy", "response_time"]
    evaluation_method: "exact_match_or_semantic_similarity"
    difficulty_levels: ["easy", "medium", "hard"]

  mathematical:
    name: "Mathematical Reasoning"
    description: "Problems requiring mathematical computation and logic"
    primary_metrics: ["accuracy", "numerical_correctness"]
    evaluation_method: "step_by_step_verification"
    difficulty_levels: ["basic", "intermediate", "advanced"]

  reasoning:
    name: "Logical Reasoning"
    description: "Problems requiring logical analysis and deduction"
    primary_metrics: ["accuracy", "logical_correctness"]
    evaluation_method: "argument_validation"
    difficulty_levels: ["basic", "intermediate", "complex"]

  creative_writing:
    name: "Creative Writing"
    description: "Tasks requiring creative and original content generation"
    primary_metrics: ["creativity", "relevance"]
    evaluation_method: "subjective_quality_assessment"
    difficulty_levels: ["simple", "moderate", "complex"]

  code_generation:
    name: "Code Generation"
    description: "Programming tasks requiring code generation"
    primary_metrics: ["accuracy", "code_quality"]
    evaluation_method: "syntax_and_logic_verification"
    difficulty_levels: ["basic", "intermediate", "advanced"]

# Statistical Analysis Configuration
statistics:
  enabled: true
  min_samples_for_analysis: 10  # Minimum evaluations for statistical validity
  confidence_level: 0.95  # Statistical confidence level
  effect_size_threshold: 0.2  # Minimum effect size for significance
  outlier_detection:
    enabled: true
    method: "iqr"  # Interquartile range method
    multiplier: 1.5

# Notification System Configuration
notifications:
  enabled: true
  channels:
    console: true
    file: true
    email: false  # Requires email configuration
    slack: false  # Requires webhook URL

  # Alert thresholds
  thresholds:
    performance_drop: 0.1    # 10% drop triggers alert
    significant_improvement: 0.15  # 15% improvement triggers alert
    cost_anomaly: 2.0        # 2x cost increase triggers alert
    accuracy_concern: 0.7    # Below 70% accuracy triggers alert

  # Email configuration (if enabled)
  email:
    server: "smtp.gmail.com"
    port: 587
    use_tls: true
    recipients: []
    sender: ""

  # Slack configuration (if enabled)
  slack:
    webhook_url: ""
    username: "AI Evaluation System"
    icon_emoji: ":robot_face:"

# Dashboard Configuration
dashboard:
  enabled: true
  host: "0.0.0.0"
  port: 5001
  auto_refresh: true
  refresh_interval: 30  # seconds
  max_recent_evaluations: 50
  chart_history_days: 7

# Scalability and Performance Settings
scalability:
  max_concurrent_evaluations: 5
  evaluation_timeout: 30  # seconds
  batch_processing: true
  cache_enabled: true
  cache_ttl: 3600  # 1 hour

# Model Registry (for tracking available models)
model_registry:
  # Currently configured models
  active_models:
    - name: "groq-llama"
      provider: "groq"
      model: "llama-3.1-8b-instant"
      capabilities: ["factual_qa", "reasoning", "creative_writing"]
      cost_per_token: 0.0005

    - name: "openrouter-claude"
      provider: "openrouter"
      model: "anthropic/claude-3-haiku"
      capabilities: ["factual_qa", "reasoning", "creative_writing", "analysis"]
      cost_per_token: 0.001

    - name: "cohere-command-nightly"
      provider: "cohere"
      model: "command-nightly"
      capabilities: ["factual_qa", "reasoning", "creative_writing"]
      cost_per_token: 0.0008

  # Future model configurations
  planned_models: []

# Data Export and Backup Settings
data_management:
  auto_backup: true
  backup_interval: 86400  # 24 hours in seconds
  backup_retention: 30    # days
  export_formats: ["json", "csv", "html_report"]
  compression: true

# Security and Privacy Settings
security:
  anonymize_data: false  # Set to true for privacy-sensitive deployments
  encrypt_exports: false
  audit_logging: true
  rate_limiting:
    enabled: true
    requests_per_minute: 60

# Development and Debugging
development:
  debug_mode: false
  verbose_logging: false
  mock_responses: false  # Use for testing without API calls
  performance_profiling: false
